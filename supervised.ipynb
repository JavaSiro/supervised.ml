{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (2.2.2)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.1)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.56.0-cp312-cp312-win_amd64.whl.metadata (103 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading matplotlib-3.10.0-cp312-cp312-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   ---------------------------------------  7.9/8.0 MB 97.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 19.2 MB/s eta 0:00:00\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---------------------------------------  11.0/11.1 MB 97.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.1 MB 97.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.1 MB 97.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 16.9 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl (220 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.56.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 62.2 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
      "Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 76.3 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Downloading scipy-1.15.1-cp312-cp312-win_amd64.whl (43.6 MB)\n",
      "   ---------------------------------------- 0.0/43.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 9.7/43.6 MB 50.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 33.3/43.6 MB 81.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.5/43.6 MB 86.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 43.6/43.6 MB 66.1 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, pyparsing, pillow, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 joblib-1.4.2 kiwisolver-1.4.8 matplotlib-3.10.0 pillow-11.1.0 pyparsing-3.2.1 scikit-learn-1.6.1 scipy-1.15.1 seaborn-0.13.2 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib seaborn scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exams.csv is already downloaded.\n",
      "college.csv is already downloaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import gdown \n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "def download_data(save_folder, dataset_name=\"salaries\"):\n",
    "    dataset_list = [\"salaries\", \"exams\", \"college\", \"cars\", \"mall\"]\n",
    "    assert dataset_name in dataset_list, f\"Choose one of the available datasets: {dataset_list}\"\n",
    "\n",
    "    file_ids = {\n",
    "        \"college\": \"1vwfMpQ4ikAI91zn1bWxP_Iqz7DTFUA9F\",\n",
    "        \"salaries\": \"1p-XtX29fgXT9CzBfpHm3t8r028gQPRhe\",\n",
    "        \"exams\": \"1TYN_sRmauaDgNYgQ-0VSHVAJvLoxKx2R\",\n",
    "        \"cars\": \"1Fi5IPdfEktnKyf3dyHmnh84a2jiXl33A\",\n",
    "        \"mall\": \"1eGWJVRNmGjfaH0o3dczBbNe_-RrW0_Jm\",\n",
    "    }\n",
    "\n",
    "    file_id = file_ids[dataset_name]\n",
    "    zip_path = os.path.join(save_folder, f\"{dataset_name}.zip\")\n",
    "    csv_path = os.path.join(save_folder, f\"{dataset_name}.csv\")\n",
    "\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    if os.path.isfile(csv_path):\n",
    "        print(f\"{dataset_name}.csv is already downloaded.\")\n",
    "        return\n",
    "\n",
    "    print(f\"⬇️ Downloading dataset: {dataset_name}...\")\n",
    "\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    gdown.download(url, zip_path, quiet=False)\n",
    "\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(\"Error: ZIP file was not downloaded!\")\n",
    "        return\n",
    "    if not zipfile.is_zipfile(zip_path):\n",
    "        print(\"Error: The downloaded file is not a valid ZIP! Check the Google Drive link.\")\n",
    "        return\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(save_folder)\n",
    "\n",
    "    os.remove(zip_path)\n",
    "\n",
    "    extracted_files = glob.glob(os.path.join(save_folder, \"*\"))\n",
    "    \n",
    "    if not extracted_files:\n",
    "        print(\"Error: No files were extracted! Check if the ZIP contains a subfolder.\")\n",
    "        return\n",
    "\n",
    "    if len(extracted_files) == 1 and os.path.isdir(extracted_files[0]):\n",
    "        extracted_files = glob.glob(os.path.join(extracted_files[0], \"*\"))\n",
    "\n",
    "    csv_files = [f for f in extracted_files if f.endswith(\".csv\")]\n",
    "\n",
    "    if not csv_files:\n",
    "        print(\"Error: No CSV files found after extraction!\")\n",
    "        return\n",
    "\n",
    "    latest_csv = max(csv_files, key=os.path.getctime)\n",
    "    shutil.move(latest_csv, csv_path)\n",
    "\n",
    "    print(f\" {dataset_name}.csv successfully downloaded and saved.\")\n",
    "\n",
    "download_data(\"datasets\", \"exams\")\n",
    "download_data(\"datasets\", \"college\")\n",
    "download_data(\"datasets\", \"cars\")\n",
    "download_data(\"datasets\", \"malls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
